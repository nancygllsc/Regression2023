---
title: "Linear Regression Model Project"
author: "Nancy Pulido"
date: "2024-08-06"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning = FALSE, message = FALSE)
```

## Introduction:

This report leverages the mtcars dataset to address two key questions:

Comparative Analysis of Transmission Types: Determine whether vehicles with automatic transmissions exhibit better fuel efficiency (measured in miles per gallon, MPG) compared to those with manual transmissions. Quantification of MPG Differences: Precisely measure and analyze the MPG difference between automatic and manual transmissions.

# Comparison of Manual and Automatic Transmissions Efficiency.

```{r libraries, include=FALSE}

library(dplyr)
library(ggplot2)
library(knitr)
library(manipulate)
library(datasets)
library(patchwork)
library(Hmisc)
library(pastecs)
library(MASS)
library(broom)
library(tidyverse)
library(car)
library(modelr)
require(stats); require(graphics);require(ggplot2);require(GGally)

```

# 1. Exploratory Data Analysis (EDA)

The mtcars dataset contains 32 observations of 11 variables:

- mpg: Miles per gallon
- cyl: Number of cylinders
- disp: Displacement (cubic inches)
- hp: Gross horsepower
- drat: Rear axle ratio
- wt: Weight (1000 lbs)
- qsec: 1/4 mile time
- vs: Engine (0 = V-shaped, 1 = straight)
- am: Transmission (0 = automatic, 1 = manual)
- gear: Number of forward gears
- carb: Number of carburetors



```{r part1, echo=FALSE,include=TRUE ,message=FALSE}

#exploratory data
  print(str(mtcars))
  #kable(head(mtcars))
  
  kable(summary(mtcars), caption = "Data Summary")
 dataDescription<-describe(mtcars)
```

## Exploratory Plots

```{r fig.height=10, fig.width=10, message=FALSE, exploratoryGraphs, echo=FALSE, message=FALSE}
#graph 1 - general
fit<- lm(mpg~.,data = mtcars)
rawSummary<-summary(fit) #all variables
rawCoef<-rawSummary$coefficients

#analyze data - raw- Graph raw data/graph -all
  # Plot the coefficients using ggplot2-
    #plot showing the coefficients of the model along with their error bars
tidy_fit <- tidy(fit)
  
g<- ggpairs(subset(mtcars),
               lower = list(continuous ="smooth", method = "loess"),
               title = "Subset MTCARS ")
g



#graph2 with respect to -am 

g2 <- ggpairs(mtcars,
                lower = list(continuous = wrap("smooth", method = "loess")),
                title = "Raw Data MTCARS by Trasnmission Type.",
                aes(colour=factor(am))
              )
g2
  

 

  
```

# Part 2: Exploratory Models
### Model mpg~. 

```{r fig.height=10, fig.width=10, message=FALSE, echo=FALSE, message=FALSE}
g1 <- ggplot(tidy_fit, aes(x = term, y = estimate)) +
    geom_point() +
    geom_errorbar(
      aes(ymin = estimate - std.error, ymax = estimate + std.error),
      width = 0.2) +
    labs(title = "Coefficients Plot Model: mpg~. ", 
         x = "Term", 
         y = "Estimate") +
    theme_minimal()
  g1


# Open a PDF graphics device
  #pdf("Coefficients Plot.pdf")
  # Generate the diagnostic plots
  par(mfrow = c(2, 2))  # Arrange plots in a 2x2 grid
  plot(fit,main="Coefficients Plot (mpg~.)")
  
  # Close the graphics device
  #dev.off()
  

```



```{r echo=FALSE, message=FALSE}
#summary report table: collects model info to be compared
  summary_df <- data.frame(
    Model = character(),
    Adj_R_Squared=numeric(),
    AIC=numeric(),
    BIC=numeric(),
    SignificantPredictors = numeric())
  
```

### Finding More Models
The methodology for this report involves a systemic approach. The code generates a report of a series of potential models, adding one variable at a time and subsequently comparing their statistical outcomes. This preliminary comparative report allows for previewing and identifying the model that best fits the data, ensuring robust and accurate predictions.
```{r echo=FALSE, message=FALSE}
# model: mpg~cyl
  
  fitCyl<- lm(mpg~cyl,data = mtcars)
  SummaryCyl<-summary(fitCyl) #all variables
  #kable(SummaryCyl$coefficients, caption = "Coefficients for model: mpg~cyl")
  
  #kable(anova(fit,fitCyl), caption = " Analysis of Variance Table Model: mpg~cyl")
  
  
  summary_df<-rbind(summary_df,
                    data.frame(Model= "mpg~cyl",
                               Adj_R_Squared=SummaryCyl$adj.r.squared,
                               AIC=AIC(fitCyl),
                               BIC=BIC(fitCyl),
                              SignificatPredictors=1))
  
  
  
```

```{r, echo=FALSE,message=FALSE}
MTCARSdataColNames <- names(mtcars)  # Get column names of the mtcars dataset
  
  # Loop through columns 3 to 10
  for (i in 3:10) {
    #single variable models
    #print(paste("Single Model: ", paste0("mpg~",MTCARSdataColNames[i])))
    singleModelFit<-lm(as.formula(paste0("mpg~",MTCARSdataColNames[i])),data=mtcars)
    SummarySingle<-summary(singleModelFit)
    coefSingleModel<-SummarySingle$coefficients
    summary_df<-rbind(summary_df,data.frame(
      Model= paste0("mpg~",MTCARSdataColNames[i]),
      Adj_R_Squared=SummarySingle$adj.r.squared,
      AIC=AIC(singleModelFit),
      BIC=BIC(singleModelFit),
        SignificatPredictors=1))
    
    
    #if (coefSingleModel[2,4] <= 0.05) {}
    #print("----------------------------------------------------------")
    #multiple variable models
    model <- paste0("+", paste(MTCARSdataColNames[3:i], collapse = " + "))
    model2<-paste0("mpg~ cyl",model)
    fit<-lm(as.formula(model2),data=mtcars)
    coef<-summary(fit)$coefficients
    rsqr<-summary(fit)$adj.r.squared
    #print("Model mpg~.")
    #print(rawCoef)
    report<-0
    
    for (p_value in coef[, 4]) {
      if (p_value <= 0.05) {
        report <- report + 1
      }
    }
    summary_df<-rbind(summary_df,data.frame(Model= model2,
                                            Adj_R_Squared=rsqr, 
                                            AIC=AIC(fit),
                                            BIC=BIC(fit),
                                            SignificatPredictors=report))
    
  
  }
  
```
### Preliminary Report
The table below presents all the models under consideration. Each model in the table was fitted using the R function lm() and evaluated using the corresponding "summary(lm)" output. The models are assessed based on the following criteria:

- Significant Predictors: The significance of each predictor was determined using the "summary(lm)\$coefficients" output, specifically by examining the p-values associated with the t-statistics (found in the Pr(\>\|t\|) column). A predictor is considered significant if its p-value is less than 0.05, indicating a strong association with the response variable. The table shows the number of significant predictors for each model.
- Adjusted R-Squared: The adjusted R-squared value, obtained from "summary(lm)\$adj.r.squared", is a crucial metric representing the proportion of variance in the dependent variable explained by the independent variables, adjusted for the number of predictors. A higher adjusted R-squared value indicates a better fit, accounting for model complexity.
- AIC and BIC: The Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) were calculated using the R functions AIC(lm) and BIC(lm), respectively. Both criteria are used for model selection, balancing the model fit and complexity trade-offs. AIC tends to select slightly more complex models, imposing a lighter penalty for additional parameters, whereas BIC is stricter, favoring simpler models as sample size increases. This report will select the models with the 4 highest adj_R_Squared, lowest AIC and BIC values as the preferred models.

```{r echo=FALSE, results='markup'}
summary_df$ModelNUmber <- seq_along(summary_df$Model)
kable(summary_df, caption = "Models Table")
```

# 4 & 5. Model Diagnostics and models validation

 

```{r echo=FALSE,message=FALSE}
#best models based on adjusted R2
  maxSigPredictors<-top_n(summary_df,n=4,Adj_R_Squared)
  RqrdHighest<-max(summary_df$Adj_R_Squared)
  kable(maxSigPredictors,caption = "Selected Models by Highest adj_R_squared")
  
  for(n in 1:length(maxSigPredictors$Model)){
    modelName<-paste0("modelF",n)
    modelF<-lm(as.formula(maxSigPredictors$Model[n]),data = mtcars)
    assign(modelName, modelF)
    assign(paste0(modelName,"VIF"),vif(modelF))
    assign(paste0(modelName,"RMSE"),rmse(modelF,mtcars))
    #plot --ggplot
    # Tidy the model fit
    tidyFit <- tidy(modelF)
    
    plotFinal <- ggplot(tidyFit, aes(x = term, y = estimate)) +
      geom_point() +
      geom_errorbar(
        aes(ymin = estimate - std.error, ymax = estimate + std.error),
        width = 0.2) +
      labs(title = paste("Plot: ",n), x = "Term", y = "Estimate") +
      theme_minimal()
    
    assign(paste0(modelName,"_GGPlot"),plotFinal)
    #plot()
    modelName2<-paste0("modelDiagnostics_",n,".pdf")
    
    # Open a PDF graphics device
    #pdf(modelName2)
    # Generate the diagnostic plots
    par(mfrow = c(2, 2))  # Arrange plots in a 2x2 grid
    plot(modelF,main=modelName2)
    
    # Close the graphics device
    #dev.off()
    
    
    #5. Validation:
    # Split the data into training and testing sets
    set.seed(123)
    train_indices <- sample(1:nrow(mtcars), size = 0.7 * nrow(mtcars))
    train_data <- mtcars[train_indices, ]
    test_data <- mtcars[-train_indices, ]
    
    # Fit the model on the training set
    train_model <- lm(modelF, data = train_data)
    
    # Predict on the test set
    predictions <- predict(train_model, newdata = test_data)
    
    # Calculate RMSE (Root Mean Squared Error)
    rmse <- sqrt(mean((test_data$mpg - predictions)^2))
    assign(paste0("ValidationRMSE",modelName),rmse)

  }
```

### Analysis 
- Anova analysis of variance tables for one or more fitted model objects.the Residual Sum of Squares (RRS), is a metric used in regression analysis to measure the variation of the data that is not explained by the model. It represents the difference between the observed values and the predicted values. A small R-Anova value indicates a good fit between the model and the data, suggesting that most of the variation is explained by the factors included in the model.

- Variance Indicator Factor (VIF) VIF values help to identify multicollinearity among predictors.Multicollinearity occurs when two or more predictors are highly correlated, leading to unstable estimates of regression coefficients.Values above 10 indicate problematic multicollinearity. 

- Root Mean Squared Error, RMSE is a measure of how well the model's predictions match the actual values. Lower RMSE indicates better model performance.

- Residual Plots: Diagnostic plots help to check the assumptions of linear regression, including linearity, homoscedasticity, and normality of residuals.


```{r echo=FALSE,message=FALSE}
  print("ANOVA")
  anova(modelF1,modelF2,modelF3,modelF4)
  vifModels<-list(modelF1VIF, modelF2VIF,modelF3VIF,modelF4VIF)
  rmseModels<-list(modelF1RMSE,modelF2RMSE,modelF3RMSE,modelF4RMSE)
  print("Variance Indicator Factor VIF")
  print(vifModels)
  print("RMSE")
  print(rmseModels)
  #plots
  
  
  
```

# 6 Corrections to Model Diagnostics 
In the analysis of variance, at first glance model 1 seems to be significant model. However, cyl and dis show high multicollinearity in all models, that ia also confirmed by the RMS. Additionally, the high RRS values suggests a better fit model exist. To address the issue, cyl and disp are removed from all 4 models and then are compared with first set. 

```{r echo=FALSE,message=FALSE}
  maxSigPredictors<-top_n(summary_df,n=4,Adj_R_Squared)
  #max(summary_df$Adj_R_Squared)
  
  for(n in 1:length(maxSigPredictors$Model)){
    modelName<-paste0("model2F_",n)
    modelString <- as.character(maxSigPredictors$Model[n])
    modelString <- sub("cyl\\+disp \\+ ", "", modelString)  # Corrected the regex pattern
    #print(modelString)
    modelF<-lm(as.formula(modelString),data = mtcars)
    assign(modelName, modelF)
    assign(paste0(modelName,"VIF"),vif(modelF))
    assign(paste0(modelName,"RMSE"),rmse(modelF,mtcars))
    #plot --ggplot
    # Tidy the model fit
    tidyFit <- tidy(modelF)
    
    plotFinal <- ggplot(tidyFit, aes(x = term, y = estimate)) +
      geom_point() +
      geom_errorbar(
        aes(ymin = estimate - std.error, ymax = estimate + std.error),
        width = 0.2) +
      labs(title = paste("Plot: ",n), x = "Term", y = "Estimate") +
      theme_minimal()
    
    assign(paste0(modelName,"_GGPlot"),plotFinal)
    #plot()
    modelName2<-paste0("model2Diagnostics_",n,".pdf")
    
    # Open a PDF graphics device
    #pdf(modelName2)
    # Generate the diagnostic plots
    par(mfrow = c(2, 2))  # Arrange plots in a 2x2 grid
    plot(modelF,main=modelName2)
    
    # Close the graphics device
    #dev.off()
    
    #5. Validation:
    # Split the data into training and testing sets
    set.seed(123)
    train_indices <- sample(1:nrow(mtcars), size = 0.7 * nrow(mtcars))
    train_data <- mtcars[train_indices, ]
    test_data <- mtcars[-train_indices, ]
    
    # Fit the model on the training set
    train_model <- lm(modelF, data = train_data)
    
    # Predict on the test set
    predictions <- predict(train_model, newdata = test_data)
    
    # Calculate RMSE (Root Mean Squared Error)
    rmse <- sqrt(mean((test_data$mpg - predictions)^2))
    assign(paste0("ValidationRMSE",modelName),rmse)
    
    
  }
```

```{r echo=FALSE,message=FALSE}
#anova
  print("ANOVA")
  anova(model2F_1,model2F_2,model2F_3,model2F_4)
  vifModels2<-list(model2F_1VIF, model2F_2VIF,model2F_3VIF,model2F_4VIF)
  rmseModels2<-list(model2F_1RMSE,model2F_2RMSE,model2F_3RMSE,model2F_4RMSE)
  print("Variance Indicator Factor VIF - Corrected Models")
  print(vifModels2)
  print("RMSE-Corrected Models")
  print(rmseModels2)

```
- anova model results: 
  in general models 2 and 3 shows an improvement in P-value. However, still not significant. 
- RRS and sum of Sq are higher compared to first set .
- VIF/RMSE the improved model shows improved VIF below 6 values and slightly larger RMSE values. 

Despite of the lack of significant improvemnts, the results hits the a rate describing force with respect to time. Which relates to the equation of power. 


### Proposed Models

Exclusion of the variables "cyl" and "disp" does not result in significant improvements in model performance compared to the initial set of models.

Given that power is defined here as the total horsepower of the car (where 1 horsepower equals 735.5 watts, or kg·m²/s²), which reflects the relationship between mass, distance, and time, two new models have been introduced. These additions aim to address the multicollinearity observed in the previous models.

1. mpg~(wt+qsec)
2. mpg~(qsec+hp)

```{r echo=FALSE,message=FALSE}
proposedLM1<-lm(mpg~(wt+qsec), data=mtcars)
proposedLM2<-lm(mpg~(qsec+hp),data=mtcars)
```

#### Diagnostic to new models

```{r  echo=FALSE,message=FALSE}
  print("ANOVA")

anova(modelF1,modelF2,modelF3,modelF4,proposedLM1,proposedLM2)

vifModels3<-list( modelF1VIF, modelF2VIF, modelF3VIF, modelF4VIF, model2F_1VIF, model2F_2VIF,model2F_3VIF,model2F_4VIF,vif(proposedLM1),(vif(proposedLM2)))

rmseModels3<-list(modelF1RMSE, modelF2RMSE, modelF3RMSE, modelF4RMSE,rmse(proposedLM1,mtcars),rmse(proposedLM2,mtcars))


  print("Variance Indicator Factor VIF - All Models")
  print(vifModels3)
  print("RMSE- All Models")
  print(rmseModels3)
  
par(mfrow = c(2, 2))  # Arrange plots in a 2x2 grid
plot(proposedLM1,main="Proposed Model 1")

par(mfrow = c(2, 2))  # Arrange plots in a 2x2 grid
plot(proposedLM2,main="Proposed Model 2")
    
    

```

### Final Model
It's important to note that the ANOVA test results align with the Q-Q Residual Plots for each model, showing that there is little statistically significant improvement, particularly in the tails. In most plots, the tails deviate noticeably from the linear regression line. However, Model 5 demonstrates a distinct pattern, where the residuals eventually return to the line. In terms of variance, Model 5 also shows the least multicollinearity according to the VIF results, despite having a significantly lower RMSE compared to the other models. Therefore, model 5 is used to predict and answers the questions proposed in this report. 

# Response to project question 1

Now that the linear model is established, it's beneficial to visualize the data before making predictions.

```{r echo=FALSE,message=FALSE}
#transmissions performance 
ggplot(mtcars,
         aes(sample=mpg,color=factor(am)))+
    stat_qq()+
    stat_qq_line()+
  labs(title = "MTCARS Gas Consumption by Transmission",
       caption = "1 = Manual Transmission. 0 = Automatic transmission")


```

Based on the graph, there's minimal difference in MPG between the two transmission types; however, manual transmissions tend to have slightly higher MPG. While it might be tempting to simply observe where the two datasets intersect to determine the difference, this report aims to analyze the overall trend. To achieve this, a simulation using R's prediction function is employed. The difference in the mean predicted MPG between the two subsets quantifies the fuel efficiency gap between manual and automatic cars.

### Prediction 

```{r  echo=FALSE,message=FALSE }
finalModel<-proposedLM1

manualTransmision<-filter(mtcars,am==1)
automaticTransmition<-filter(mtcars,am==0) 

 auto_pred<- predict(finalModel, newdata = automaticTransmition)
 manual_pred<-predict(finalModel,newdata = manualTransmision)

 # Compare the predicted values
print("Automatic Transmission")
auto_pred
print("Manual Transmission")
manual_pred 

# Mean predicted mpg for automatic cars
mean_auto_pred <- mean(auto_pred)

# Mean predicted mpg for manual cars
mean_manual_pred <- mean(manual_pred)

# Difference in mpg
mpg_difference <- mean_manual_pred - mean_auto_pred
print("Mean Difference")
mpg_difference

```

# Results: 
Automatic transmissions are more mpg efficient than manual transmissions. by a factor of 6.090 mpg. Which makes sense because automatic transmissions selects the right gear without driver input. 


```{r echo=FALSE,message=FALSE}
# Create a data frame for ggplot2
data <- data.frame(
  Dataset = factor(c("Manual", "Automatic")),
  Mean = c(mean_manual_pred, mean_auto_pred)
)


ggplot(data, aes(x = Dataset, y = Mean)) +
  geom_point(size = 4, color = "blue") +
  geom_line(aes(group = 1), color = "red", linetype = "dashed") +
  labs(title = "Automatic and Manual Transmissions Dataset Means Comparison",
       x = "Dataset", y = "Mean Value") +
  theme_minimal()
```
